{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Toy Neural Network \n",
    "## The MNIST Dataset\n",
    "Sources:\n",
    "- PyTorch tutorial: https://www.youtube.com/watch?v=c36lUUr864M&t=320s  \n",
    "- Hands-On Machine Learning\n",
    "- Deep Learning with PyTorch\n",
    "\n",
    "The purpose of this toy model is to produce a functioning neural network using PyTorch - the details regarding choice of network structure, hyperparameters, loss/activation function etc. will be explored later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the MNIST dataset which contains thousands of (labeled) handwritten digits which can be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70000 instances with 784 data points each. These are related to the pixels of a 28 x 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example image\n",
    "plt.imshow(mnist.data[125].reshape(28, 28), cmap='gray')\n",
    "plt.title(mnist.target[125])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mnist.data/255, mnist.target.astype(np.int), # data / 255 to scale data\n",
    "                                                   train_size= 0.6, test_size=0.4, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These need to be converted to tensors for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(x_train)\n",
    "x_test = torch.Tensor(x_test)\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5059,\n",
       "         0.8549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.9961, 0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.0000, 0.0000, 0.4824, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.4784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7137, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1569, 0.0000, 0.0000, 0.9725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.6980, 0.0000, 0.0000, 0.9922, 0.0000, 0.9922, 0.9922,\n",
       "         0.0000, 0.9922, 0.0000, 0.0000, 0.5922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.9922, 0.0000, 0.0000, 0.0627, 0.0000, 0.0627, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of two elements from the x_train tensor\n",
    "x_train[:2, ::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model  \n",
    "We can define some hyperparameters for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the NN in batches, we can use the **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader([[x_train[i], y_train[i]] for i in range(len(y_train))], batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader([[x_test[i], y_test[i]] for i in range(len(y_test))], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader is an iterable object that seperates the data into batches with # instances = *batch_size*. The batch size, as well as the other hyperparameters, affect how fast the model is trained and how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784]) tensor([4., 6., 4., 3., 3., 4., 4., 9., 7., 8., 7., 4., 6., 6., 8., 9., 3., 4.,\n",
      "        4., 8., 4., 7., 0., 0., 3., 7., 4., 2., 3., 6., 1., 3., 7., 4., 1., 6.,\n",
      "        8., 3., 1., 8., 9., 2., 0., 8., 8., 0., 7., 0., 7., 3., 8., 8., 2., 5.,\n",
      "        6., 6., 4., 9., 1., 9., 2., 3., 0., 1., 7., 4., 4., 9., 9., 9., 6., 2.,\n",
      "        1., 4., 3., 3., 4., 9., 9., 3., 6., 3., 7., 5., 6., 6., 9., 8., 3., 1.,\n",
      "        9., 2., 6., 9., 2., 2., 2., 5., 9., 7.])\n"
     ]
    }
   ],
   "source": [
    "# Example of a training batch\n",
    "ex_sample, ex_label = next(iter(train_loader))\n",
    "print(ex_sample.shape, ex_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the model. Since we are not making a customised model, using sequential will be quicker and less prone to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                nn.Linear(784, 300), # input layer = 784, output = 300 --> hidden layer\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(300, 10))  #  hidden layer = 300, output layer = 10 --> classes 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model has 784 features, 2 hidden layers with 300 and 10 neurons, respectively, and the activation function between the two layers is the rectified linear unit (ReLU)\n",
    "\n",
    "$$ \\text{ReLU}(x) = \\text{max}(0, x) = \\begin{cases}\n",
    "       x  & \\text{if $x > 0$,}\\\\\n",
    "      0 & \\text{$ x \\leq 0$.}\n",
    "    \\end{cases} $$\n",
    "    \n",
    "The softmax activation function is not required after the last layer because it will be included with the cross entropy loss funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is the cross entrpoy loss, defined as\n",
    "\n",
    "$$ l_n = -w_{y_n} \\log{\\frac{\\exp{x_{n,y_n}}}{\\sum_{c=0}^C \\exp{x_{n,c}}}}, $$\n",
    "\n",
    "for a given bacth $n$.  \n",
    "The Adam optimiser adjusts the learning rate during training which controls how fast the model adapts to changing data.  \n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/Toy_NN/tb/run2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 100/420, loss = 0.387500\n",
      "epoch 1, step 200/420, loss = 0.264137\n",
      "epoch 1, step 300/420, loss = 0.292863\n",
      "epoch 1, step 400/420, loss = 0.258061\n",
      "epoch 2, step 100/420, loss = 0.137585\n",
      "epoch 2, step 200/420, loss = 0.135655\n",
      "epoch 2, step 300/420, loss = 0.204118\n",
      "epoch 2, step 400/420, loss = 0.157109\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (instances, labels) in enumerate(train_loader): # i gets the index\n",
    "        \n",
    "        # forward pass\n",
    "        out = model(instances)\n",
    "        #print(out)\n",
    "        #print(labels.long())\n",
    "        loss = loss_fn(out, labels.long()) # .long() gets the labels in the correct integer format\n",
    "\n",
    "        # backward pass\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # parameter update\n",
    "        optimiser.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1}, step {i+1}/{n_total_steps}, loss = {loss:.6f}')\n",
    "        \n",
    "        writer.add_scalar('loss', loss, global_step = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18056), started 0:04:07 ago. (Use '!kill 18056' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-788055b21b3b8d61\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-788055b21b3b8d61\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.956\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "\n",
    "n_samples = 0\n",
    "n_correct = 0\n",
    "\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad(): # no_grad means the model will not be trained while we test\n",
    "    for instances, labels in test_loader:\n",
    "        output = model(instances)\n",
    "        _, predictions = torch.max(output, 1) # prediction is taken as the class with the highest probability\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        test_preds.append(predictions)\n",
    "        test_labels.append(labels)\n",
    "        \n",
    "    acc = n_correct/n_samples\n",
    "    print(f'accuracy = {acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualise the model's performance is by using a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 8,  ..., 3, 4, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cat = torch.cat(test_preds)\n",
    "labels_cat = torch.cat(test_labels)\n",
    "preds_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 8,  ..., 3, 4, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2595,    0,   14,   11,    7,   13,   21,    5,    7,   16],\n",
       "       [   0, 3099,    5,   11,    7,    7,    7,    9,   26,   10],\n",
       "       [   4,   22, 2714,   49,    8,    6,    6,   27,   13,    2],\n",
       "       [   2,    5,   14, 2632,    1,   20,    0,    4,   32,   16],\n",
       "       [   3,    3,   12,    1, 2597,    8,   13,   26,    6,   39],\n",
       "       [   5,    6,    2,   72,    1, 2408,   39,    3,   19,   13],\n",
       "       [   8,    1,    3,    2,   15,   15, 2698,    0,   12,    2],\n",
       "       [   4,    9,   15,   23,    6,    7,    0, 2789,    3,   34],\n",
       "       [  19,   20,   28,   39,    9,   24,   11,    5, 2582,   15],\n",
       "       [   2,    8,    4,   39,   82,   25,    0,   38,   25, 2656]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(preds_cat, labels_cat)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect classifier would produce a diagonal matrix.  We can visualise this matrix as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_matrix, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then look at errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "norm_conf_matrix = conf_matrix / row_sums\n",
    "np.fill_diagonal(norm_conf_matrix, 0)\n",
    "plt.matshow(norm_conf_matrix, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this shows that 5's are frequently misclassified as 3's.  \n",
    "\n",
    "If we now want to save the trained model, it is recomended to save the model parameters and then rebuild the model at a later time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNIST_Model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same\n",
      "same\n",
      "same\n",
      "same\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "\n",
    "loaded_model = nn.Sequential(\n",
    "                nn.Linear(784, 300),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(300, 10)) \n",
    "\n",
    "loaded_model.load_state_dict(torch.load('MNIST_Model.pth'))\n",
    "\n",
    "for i, j in zip(model.state_dict(), loaded_model.state_dict()):\n",
    "    if i != j:\n",
    "        print('Not the same')\n",
    "    else:\n",
    "        print('same')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
